{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3974cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks(file_path:Path) -> List[Dict]:\n",
    "    chunks=[]\n",
    "    if not file_path.exists():\n",
    "        return chunks\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                if not line.strip():\n",
    "                    print(f\"‚ö†Ô∏è  L√≠nea {line_num} est√° vac√≠a\")\n",
    "                    continue\n",
    "                try: \n",
    "                    chunks.append(json.loads(line))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è  Error en l√≠nea {line_num} de {file_path}: {e}\")\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error leyendo {file_path}: {e}\")\n",
    "    \n",
    "    return chunks\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def filter_chunk_quality(chunk: Dict, min_words: int = 50, max_words: int = 2000) -> Optional[str]:\n",
    "\n",
    "    text = chunk.get('content')\n",
    "    if not text or not text.strip():\n",
    "        return None\n",
    "    \n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    if word_count < min_words:\n",
    "        return None\n",
    "    \n",
    "    if word_count > max_words:\n",
    "        text = ' '.join(words[:max_words])\n",
    "        word_count = max_words\n",
    "        \n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e96691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_text_with_context(text: str, metadata: Dict, include_context: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Formatea texto con contexto opcional\n",
    "    \n",
    "    Args:\n",
    "        text: Texto del chunk\n",
    "        metadata: Metadata del chunk\n",
    "        include_context: Si incluir contexto en el texto\n",
    "    \n",
    "    Returns:\n",
    "        Texto formateado\n",
    "    \"\"\"\n",
    "    if not include_context:\n",
    "        return text\n",
    "    \n",
    "    # Construir contexto\n",
    "    context_parts = []\n",
    "    \n",
    "    # Informaci√≥n del documento\n",
    "    title = metadata.get('doc_title') or metadata.get('title', '')\n",
    "    if title:\n",
    "        context_parts.append(f\"Document: {title}\")\n",
    "    \n",
    "    source_type = metadata.get('source_type', '')\n",
    "    if source_type:\n",
    "        context_parts.append(f\"Source: {source_type}\")\n",
    "    \n",
    "    # Campos comunes del metadata\n",
    "    category = metadata.get('category', '')\n",
    "    if category:\n",
    "        context_parts.append(f\"Category: {category}\")\n",
    "    \n",
    "    section_title = metadata.get('section_title')\n",
    "    if section_title:\n",
    "        context_parts.append(f\"Section: {section_title}\")\n",
    "    \n",
    "    section_level = metadata.get('section_level')\n",
    "    if section_level is not None:\n",
    "        context_parts.append(f\"Section Level: {section_level}\")\n",
    "    \n",
    "    page_num_real = metadata.get('page_num_real')\n",
    "    if page_num_real is not None:\n",
    "        context_parts.append(f\"Page (real): {page_num_real}\")\n",
    "    \n",
    "    page_num_logical = metadata.get('page_num_logical')\n",
    "    if page_num_logical is not None:\n",
    "        context_parts.append(f\"Page (logical): {page_num_logical}\")\n",
    "    \n",
    "    # Contexto espec√≠fico por fuente (MITRE)\n",
    "    if 'tactic' in metadata:\n",
    "        context_parts.append(f\"MITRE Tactic: {metadata['tactic']}\")\n",
    "    \n",
    "    if 'technique_id' in metadata:\n",
    "        context_parts.append(f\"MITRE Technique: {metadata['technique_id']}\")\n",
    "    \n",
    "    if context_parts:\n",
    "        context = \"\\n\".join(context_parts)\n",
    "        return f\"{context}\\n\\n{text}\"\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894e6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7f3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CASO DE PRUEBA: Cargar chunks desde archivo JSONL\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# CASO DE PRUEBA: Cargar chunks desde un archivo real\n",
    "print(\"=\" * 70)\n",
    "print(\"CASO DE PRUEBA: Cargar chunks desde archivo JSONL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Usar un archivo real del proyecto\n",
    "# test_file = Path(\"data/chunks/MITRE/pages.chunks.jsonl\")\n",
    "test_file = Path(\"/Users/marcosespana/Desktop/U/DatosTesis/data/chunks/AISecKG/pages.chunks.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473d42eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Archivo: /Users/marcosespana/Desktop/U/DatosTesis/data/chunks/AISecKG/pages.chunks.jsonl\n",
      "   Existe: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nüìÇ Archivo: {test_file}\")\n",
    "print(f\"   Existe: {test_file.exists()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a4bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total de chunks cargados: 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar chunks\n",
    "chunks = load_chunks(test_file)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"‚úÖ Total de chunks cargados: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "875162c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Primer chunk:\n",
      "   Keys disponibles: ['id', 'content', 'metadata']\n",
      "   Analysis Point 4: What is your observation of the responding time of each type of scans, and what is the reason and implications? 3.2.4 IP ID (Idle) scanning 1. Find at least one accessible (open or c...\n",
      "\n",
      "   Contenido:\n",
      "   Analysis Point 4: What is your observation of the responding time of each type of scans, and what is the reason and implications? 3.2.4 IP ID (Idle) scanning 1. Find at least one accessible (open or c...\n",
      "\n",
      "   Metadata:\n",
      "     - category: NarrativeText\n",
      "     - section_title: None\n",
      "     - section_level: 0\n",
      "     - page_num_real: None\n",
      "     - page_num_logical: None\n"
     ]
    }
   ],
   "source": [
    "if chunks:\n",
    "    print(f\"\\nüìÑ Primer chunk:\")\n",
    "    first_chunk = chunks[0]\n",
    "    print(f\"   Keys disponibles: {list(first_chunk.keys())}\")\n",
    "    \n",
    "    # Mostrar contenido (primeros 200 caracteres)\n",
    "    content = first_chunk.get('content', first_chunk.get('text', ''))\n",
    "    print(f\"   {content[:200]}...\")\n",
    "    if \"content\" in first_chunk:\n",
    "        print(f\"\\n   Contenido:\")\n",
    "        content = first_chunk['content']\n",
    "        print(f\"   {content[:200]}...\")\n",
    "        \n",
    "    if \"metadata\" in first_chunk:\n",
    "        print(f\"\\n   Metadata:\")\n",
    "        metadata = first_chunk['metadata']\n",
    "        for key, value in list(metadata.items())[:5]:\n",
    "            print(f\"     - {key}: {value}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if chunks:\n",
    "#     print(f\"\\nüìÑ Primer chunk:\")\n",
    "#     first_chunk = chunks[0]\n",
    "#     print(f\"   Keys disponibles: {list(first_chunk.keys())}\")\n",
    "    \n",
    "#     # Mostrar contenido (primeros 200 caracteres)\n",
    "#     content = first_chunk.get('content', first_chunk.get('text', ''))\n",
    "#     if content:\n",
    "#         print(f\"\\n   Contenido (primeros 200 chars):\")\n",
    "#         print(f\"   {content[:200]}...\")\n",
    "    \n",
    "#     # Mostrar metadata si existe\n",
    "#     if 'metadata' in first_chunk:\n",
    "#         print(f\"\\n   Metadata:\")\n",
    "#         metadata = first_chunk['metadata']\n",
    "#         for key, value in list(metadata.items())[:5]:  # Primeros 5 campos\n",
    "#             print(f\"     - {key}: {value}\")\n",
    "    \n",
    "#     print(f\"\\nüìä Resumen:\")\n",
    "#     print(f\"   - Total chunks: {len(chunks)}\")\n",
    "#     print(f\"   - Estructura del primer chunk: {type(first_chunk)}\")\n",
    "#     print(f\"   - Campos del chunk: {len(first_chunk)} campos\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è  No se cargaron chunks (archivo vac√≠o o no existe)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
