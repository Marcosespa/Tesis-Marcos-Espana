# =============================================================================
# CONFIGURACIÓN PARA CHUNKING CON GPU
# =============================================================================
# Copia este archivo como .env y ajusta los valores según tu servidor

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE GPU
# -----------------------------------------------------------------------------
# Opción 1: Especificar dispositivo completo (recomendado)
# GPU_DEVICE=cuda:1

# Opción 2: Especificar solo ID de GPU (se usará como cuda:ID)
GPU_ID=1

# NOTA: El código usará automáticamente la GPU 1 (cuda:1) si CUDA está disponible
# Para usar otra GPU, descomenta GPU_DEVICE y cambia el número
# Para usar CPU, establece: GPU_DEVICE=cpu

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE MODELOS
# -----------------------------------------------------------------------------
# Modelo de embeddings (recomendado: all-MiniLM-L6-v2)
EMBED_MODEL=all-MiniLM-L6-v2

# Modelo para conteo de tokens
TOKEN_MODEL=gpt-4o-mini

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE CHUNKING
# -----------------------------------------------------------------------------
# Tamaños de chunks (en tokens)
TARGET_TOKENS=200
MIN_TOKENS=100
MAX_TOKENS=256

# Overlapping entre chunks (0.0 - 1.0)
OVERLAP_RATIO=0.18

# Configuración semántica
SEM_WIN_TOKENS=150
SEM_STEP_TOKENS=30
SMOOTH_K=5
MAD_Z_THRESH=2.5

# Configuración estructural
STRUCTURE_WEIGHT=0.8
MAX_SNAP_DISTANCE=50

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE WEAVIATE (si usas vector database)
# -----------------------------------------------------------------------------
# WEAVIATE_URL=http://localhost:8080
# WEAVIATE_API_KEY=your_api_key_here

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE LOGGING
# -----------------------------------------------------------------------------
# Nivel de logging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# CONFIGURACIÓN DE MEMORIA
# -----------------------------------------------------------------------------
# Límite de memoria para procesamiento (en GB)
MAX_MEMORY_GB=8

# -----------------------------------------------------------------------------
# NOTAS DE CONFIGURACIÓN
# -----------------------------------------------------------------------------
# 1. GPU_DEVICE tiene prioridad sobre GPU_ID
# 2. Si no especificas GPU_DEVICE ni GPU_ID, usará cuda:1 por defecto
# 3. Para usar CPU, establece: GPU_DEVICE=cpu
# 4. Para múltiples GPUs, puedes especificar: GPU_DEVICE=cuda:0,1,2,3
# 5. Los valores numéricos se convierten automáticamente desde strings
